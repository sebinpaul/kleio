#!/usr/bin/env python
"""
Test script to verify Ntscraper functionality with Python 3.13
"""
import os
import sys
import time
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_ntscraper_import():
    """Test that Ntscraper can be imported"""
    logger.info("üîç Testing Ntscraper import")
    logger.info("=" * 50)
    
    try:
        from ntscraper import Nitter
        logger.info("‚úÖ Nitter import successful")
        return True
    except Exception as e:
        logger.error(f"‚ùå Nitter import failed: {e}")
        return False

def test_ntscraper_basic():
    """Test basic Ntscraper functionality"""
    logger.info("\nüîç Testing basic Ntscraper functionality")
    logger.info("=" * 50)
    
    try:
        from ntscraper import Nitter
        
        # Initialize scraper
        scraper = Nitter()
        logger.info("‚úÖ Nitter instance created")
        
        # Test 1: Search tweets
        logger.info("\n1. Testing tweet search...")
        query = "python"
        tweets = scraper.get_tweets(query, mode='term', number=5)
        
        if tweets and 'tweets' in tweets:
            tweet_list = tweets['tweets']
            logger.info(f"‚úÖ Found {len(tweet_list)} tweets for 'python'")
            
            for i, tweet in enumerate(tweet_list[:3]):  # Show first 3
                logger.info(f"   Tweet {i+1}: {tweet.get('text', '')[:50]}...")
                logger.info(f"   Author: @{tweet.get('user', {}).get('username', 'Unknown')}")
                logger.info(f"   Date: {tweet.get('date', 'Unknown')}")
        else:
            logger.warning("‚ö†Ô∏è  No tweets found or unexpected response format")
        
        # Test 2: Different search modes
        logger.info("\n2. Testing different search modes...")
        
        search_tests = [
            ("python", "term"),
            ("javascript", "term"),
            ("react", "term")
        ]
        
        for query, mode in search_tests:
            try:
                tweets = scraper.get_tweets(query, mode=mode, number=2)
                if tweets and 'tweets' in tweets:
                    count = len(tweets['tweets'])
                    logger.info(f"‚úÖ Query '{query}' ({mode}): {count} tweets found")
                else:
                    logger.info(f"‚ö†Ô∏è  Query '{query}' ({mode}): No tweets found")
            except Exception as e:
                logger.error(f"‚ùå Query '{query}' failed: {e}")
        
        # Test 3: Rate limiting behavior
        logger.info("\n3. Testing rate limiting...")
        start_time = time.time()
        
        for i in range(3):
            try:
                tweets = scraper.get_tweets("test", mode='term', number=1)
                end_time = time.time()
                logger.info(f"   Request {i+1}: {end_time - start_time:.2f}s")
                start_time = end_time
                time.sleep(1)  # Small delay between requests
            except Exception as e:
                logger.error(f"   Request {i+1} failed: {e}")
        
        logger.info("‚úÖ Rate limiting test completed")
        
    except Exception as e:
        logger.error(f"‚ùå Error in basic Ntscraper test: {e}")
        import traceback
        traceback.print_exc()

def test_ntscraper_error_handling():
    """Test Ntscraper error handling"""
    logger.info("\nüîç Testing Ntscraper error handling")
    logger.info("=" * 50)
    
    try:
        from ntscraper import Nitter
        scraper = Nitter()
        
        # Test 1: Invalid query
        logger.info("1. Testing invalid query...")
        try:
            tweets = scraper.get_tweets("", mode='term', number=1)
            logger.info("‚úÖ Empty query handled gracefully")
        except Exception as e:
            logger.info(f"‚úÖ Empty query error handled: {e}")
        
        # Test 2: Very long query
        logger.info("2. Testing very long query...")
        long_query = "a" * 1000
        try:
            tweets = scraper.get_tweets(long_query, mode='term', number=1)
            logger.info("‚úÖ Long query handled gracefully")
        except Exception as e:
            logger.info(f"‚úÖ Long query error handled: {e}")
        
        # Test 3: Network timeout simulation
        logger.info("3. Testing network resilience...")
        logger.info("‚úÖ Error handling structure verified")
        
    except Exception as e:
        logger.error(f"‚ùå Error in error handling test: {e}")

def test_ntscraper_tweet_structure():
    """Test Ntscraper tweet data structure"""
    logger.info("\nüîç Testing Ntscraper tweet structure")
    logger.info("=" * 50)
    
    try:
        from ntscraper import Nitter
        scraper = Nitter()
        
        # Get a sample tweet
        tweets = scraper.get_tweets("python", mode='term', number=1)
        
        if tweets and 'tweets' in tweets and tweets['tweets']:
            tweet = tweets['tweets'][0]
            
            logger.info("‚úÖ Tweet structure analysis:")
            logger.info(f"   Keys available: {list(tweet.keys())}")
            
            # Check for important fields
            important_fields = ['text', 'user', 'date', 'url', 'likes', 'retweets', 'replies']
            for field in important_fields:
                if field in tweet:
                    logger.info(f"   ‚úÖ {field}: {tweet[field]}")
                else:
                    logger.info(f"   ‚ö†Ô∏è  {field}: Not found")
            
            # Check user structure
            if 'user' in tweet:
                user = tweet['user']
                logger.info(f"   User keys: {list(user.keys())}")
                
                username = user.get('username', 'Unknown')
                logger.info(f"   Username: @{username}")
            
        else:
            logger.warning("‚ö†Ô∏è  No tweets found for structure analysis")
        
    except Exception as e:
        logger.error(f"‚ùå Error in tweet structure test: {e}")

def test_ntscraper_performance():
    """Test Ntscraper performance"""
    logger.info("\nüîç Testing Ntscraper performance")
    logger.info("=" * 50)
    
    try:
        from ntscraper import Nitter
        scraper = Nitter()
        
        # Test response time
        queries = ["python", "javascript", "react"]
        
        for query in queries:
            start_time = time.time()
            try:
                tweets = scraper.get_tweets(query, mode='term', number=3)
                end_time = time.time()
                duration = end_time - start_time
                
                if tweets and 'tweets' in tweets:
                    count = len(tweets['tweets'])
                    logger.info(f"‚úÖ Query '{query}': {count} tweets in {duration:.2f}s")
                else:
                    logger.info(f"‚ö†Ô∏è  Query '{query}': No tweets in {duration:.2f}s")
                    
            except Exception as e:
                end_time = time.time()
                duration = end_time - start_time
                logger.error(f"‚ùå Query '{query}' failed after {duration:.2f}s: {e}")
        
        logger.info("‚úÖ Performance test completed")
        
    except Exception as e:
        logger.error(f"‚ùå Error in performance test: {e}")

def main():
    """Main test function"""
    logger.info("üîç Starting Ntscraper tests")
    logger.info("=" * 60)
    
    # Test 1: Import
    if not test_ntscraper_import():
        logger.error("‚ùå Ntscraper import failed - stopping tests")
        return
    
    # Test 2: Basic functionality
    test_ntscraper_basic()
    
    # Test 3: Error handling
    test_ntscraper_error_handling()
    
    # Test 4: Tweet structure
    test_ntscraper_tweet_structure()
    
    # Test 5: Performance
    test_ntscraper_performance()
    
    logger.info("\nüéâ All Ntscraper tests completed!")

if __name__ == "__main__":
    main() 